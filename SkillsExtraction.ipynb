{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "print_debug = True\n",
    "csv_file = './examples/cv.csv' # the csv text data include the following fields: id (int), text (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and clean data\n",
      "    id                                               text\n",
      "0  1.0  \"job title: software engineer\\ncompany: xyz te...\n",
      "1  2.0  \"job title: data scientist\\ncompany: abc data\\...\n",
      "4  3.0  \"resume\\nname: john doe\\ncontact: john.doe@exa...\n",
      "5  4.0  \"resume\\nname: jane smith\\ncontact: jane.smith...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and clean data\n",
    "print('Load and clean data')\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df.dropna()\n",
    "df['text'] = df['text'].str.lower()\n",
    "if print_debug:\n",
    "    print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ID: 0\n",
      "\tSoft Skills\n",
      "['passionate', 'design and develop software solutions', 'gathering user requirements', 'defining system functionality', 'writing code', 'analytical mind', 'problem - solving aptitude', 'work independently', 'organizational and leadership skills']\n",
      "\tHard Skills\n",
      "['software', 'java', 'ruby on rails', '. net programming languages', 'jscript. net', 'software development', 'scripting', 'project management', 'system monitoring tools', 'new relic', 'automated testing frameworks', 'selected programming languages', 'c + +', 'java / j2ee platform', 'relational databases', 'mysql', 'nosql databases']\n",
      "CV ID: 1\n",
      "\tSoft Skills\n",
      "['analyze large amounts of raw information', 'find patterns', 'conducting full lifecycle analysis', ', activities and design', 'develop analysis and reporting capabilities', 'monitor performance and quality control plans', 'identify improvements', 'analytical mind', 'business acumen', 'math skills', 'problem - solving aptitude', 'communication and presentation skills']\n",
      "\tHard Skills\n",
      "['data nlocation', 'new', 'ny njob', 'nproven', 'data', 'data mining', 'machine learning', 'operations research', 'r', 'sql', 'python', 'scala', 'java', 'c + +', 'business intelligence', 'tableau', 'data frameworks', 'hadoop )', 'math', 'statistics', 'algebra']\n",
      "CV ID: 4\n",
      "\tSoft Skills\n",
      "['developed and maintained various web applications', 'managed cloud resources', 'lead a team of 5 junior software engineers']\n",
      "\tHard Skills\n",
      "['computer science', 'stanford university', 'python, java, c + +', 'django', 'flask, spring framework', 'aws, google cloud', 'xyz tech', 'web applications', 'django', 'flask', 'cloud']\n",
      "CV ID: 5\n",
      "\tSoft Skills\n",
      "[]\n",
      "\tHard Skills\n",
      "['data science', 'harvard university', 'python', 'r', 'sql', 'tableau', 'powerbi', 'statistics', 'machine learning', 'analytical skills', 'data scientist', 'abc data', '2016', 'predictive models', 'machine learning algorithms', 'data analysis', 'python', 'r', 'created dashboards', 'tableau', 'powerbi']\n",
      "CV ID: 11\n",
      "\tSoft Skills\n",
      "['problem - solving skills']\n",
      "\tHard Skills\n",
      "['python', 'java', 'c + +', 'django', 'flask', 'spring', 'aws', 'google cloud']\n",
      "CV ID: 12\n",
      "\tSoft Skills\n",
      "['communication skills', 'leadership skills', 'strategic planning']\n",
      "\tHard Skills\n",
      "['content creation', 'seo, sem', 'google analytics', 'social media platforms']\n",
      "CV ID: 13\n",
      "\tSoft Skills\n",
      "[]\n",
      "\tHard Skills\n",
      "['python', 'r, sql', 'data visualization tools', 'tableau', 'powerbi', 'statistics', 'machine learning algorithms']\n",
      "CV ID: 14\n",
      "\tSoft Skills\n",
      "['interpersonal skills', 'organizational skills', 'decision - making skills']\n",
      "\tHard Skills\n",
      "['hris', 'performance management', 'recruitment']\n",
      "CV ID: 15\n",
      "\tSoft Skills\n",
      "[]\n",
      "\tHard Skills\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "# Load pre-trained models \n",
    "# soft skills extraction: https://huggingface.co/jjzha/jobbert_skill_extraction\n",
    "# hard skills extraction: https://huggingface.co/jjzha/jobbert_knowledge_extraction\n",
    "token_soft_skill_classifier = pipeline(model='jjzha/jobbert_skill_extraction', aggregation_strategy='first')\n",
    "token_hard_skill_classifier = pipeline(model='jjzha/jobbert_knowledge_extraction', aggregation_strategy='first')\n",
    "\n",
    "def aggregate_skill_span(results):\n",
    "    \"\"\"Aggregate consecutive classified ntities into one.\n",
    "    \"\"\"    \n",
    "    new_results = []\n",
    "    current_result = results[0]\n",
    "\n",
    "    for result in results[1:]:\n",
    "        if result[\"start\"] <= current_result[\"end\"] + 1:\n",
    "            current_result[\"word\"] += \" \" + result[\"word\"]\n",
    "            current_result[\"end\"] = result[\"end\"]\n",
    "        else:\n",
    "            new_results.append(current_result)\n",
    "            current_result = result\n",
    "\n",
    "    new_results.append(current_result)\n",
    "    \n",
    "    # remove invalid skills that are 1 character and none-alphabet (e.g. punctuation or other symbols that are wrongly classifierd)\n",
    "    new_results = [x for x in new_results if (len(x[\"word\"]) > 1 or x[\"word\"].isalpha())]\n",
    "\n",
    "    # remove invalid skills that are all numeric\n",
    "    new_results = [x for x in new_results if (not x[\"word\"].isnumeric())]\n",
    "\n",
    "    return [x for x in new_results if (len(x[\"word\"]) > 1 or x[\"word\"].isalpha())]\n",
    "\n",
    "def extract_skill_entities(text):\n",
    "    \"\"\"Extract both soft and hard skills\n",
    "    \"\"\"   \n",
    "    # soft skills     \n",
    "    output_soft_skills = token_soft_skill_classifier(text)\n",
    "    for result in output_soft_skills:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Soft Skill\"\n",
    "            del result[\"entity_group\"]\n",
    "    # hard skills\n",
    "    output_hard_skills = token_hard_skill_classifier(text)\n",
    "    for result in output_hard_skills:\n",
    "        if result.get(\"entity_group\"):\n",
    "            result[\"entity\"] = \"Hard Skill\"\n",
    "            del result[\"entity_group\"]\n",
    "    # aggregates\n",
    "    if len(output_soft_skills) > 0:\n",
    "        output_soft_skills = aggregate_skill_span(output_soft_skills)\n",
    "    if len(output_hard_skills) > 0:\n",
    "        output_hard_skills = aggregate_skill_span(output_hard_skills)\n",
    "\n",
    "\n",
    "    return output_soft_skills, output_hard_skills\n",
    "\n",
    "# Copy dataframe and create placeholder for soft and hard skills\n",
    "out_df = df.copy(deep=True)\n",
    "out_df['soft_skills'] = pd.Series(dtype='string')\n",
    "out_df['hard_skills'] = pd.Series(dtype='string')\n",
    "\n",
    "# Loop through each row\n",
    "score_thres = 0.5\n",
    "for i, row in out_df.iterrows():\n",
    "    output_soft_skills, output_hard_skills = extract_skill_entities(row['text'])\n",
    "\n",
    "    # Extract soft skills\n",
    "    soft_skills = set()\n",
    "    for soft_skill in output_soft_skills:\n",
    "        if soft_skill['score'] > score_thres:\n",
    "            soft_skills.add(soft_skill['word'])\n",
    "    if soft_skills:\n",
    "        out_df.at[i,'soft_skills'] = str(soft_skills)\n",
    "    \n",
    "    # Extract hard skills\n",
    "    hard_skills = set()\n",
    "    for hard_skill in output_hard_skills:\n",
    "        if hard_skill['score'] > score_thres:\n",
    "            hard_skills.add(hard_skill['word'])\n",
    "    if hard_skills:\n",
    "        out_df.at[i,'hard_skills'] = str(hard_skills)\n",
    "\n",
    "    if print_debug:\n",
    "        print(f'CV ID: {i}')\n",
    "        print('\\tSoft Skills')\n",
    "        print(soft_skills)\n",
    "        print('\\tHard Skills')\n",
    "        print(hard_skills)\n",
    "\n",
    "out_df.to_csv('./output/cv_classified.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
